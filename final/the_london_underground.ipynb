{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The London Underground\n",
    "\n",
    "## A Normal Day in London\n",
    "\n",
    "### Load Needed Corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**weather**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathers = json.loads(open(\"../School/corpora/data/science/weather_conditions.json\").read())[\"conditions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adjectives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = json.loads(open(\"../School/corpora/data/words/adjs.json\").read())[\"adjs\"]\n",
    "adjectives += json.loads(open(\"../School/corpora/data/words/adjs2.json\").read())[\"adjs\"]\n",
    "\n",
    "colors = json.loads(open(\"../School/corpora/data/colors/xkcd.json\").read())[\"colors\"]\n",
    "\n",
    "for color in colors:\n",
    "    adjectives.append(color[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**movement_verbs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_verbs = [\n",
    "    'boarded',\n",
    "    'hopped',\n",
    "    'climbed',\n",
    "    'stepped',\n",
    "    'ran',\n",
    "    'jumped',\n",
    "    'shimmied',\n",
    "    'got',\n",
    "    'entered',\n",
    "    'embarked',\n",
    "    'burst',\n",
    "    'bounded',\n",
    "    'leapt',\n",
    "    'sprung',\n",
    "    'walked',\n",
    "    'scrambled',\n",
    "    'strode',\n",
    "    'moved',\n",
    "    'sprinted',\n",
    "    'darted',\n",
    "    'dashed',\n",
    "    'turned',\n",
    "    'crossed'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prepositions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepositions = json.loads(open(\"../School/corpora/data/words/prepositions.json\").read())[\"prepositions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = json.loads(open(\"../School/corpora/data/objects/objects.json\").read())[\"objects\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**venues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_file = json.loads(open(\"../School/corpora/data/geography/venues.json\").read())\n",
    "\n",
    "venues = []\n",
    "for category in venues_file[\"categories\"]:\n",
    "    for venue in category[\"categories\"]:\n",
    "        venues.append(venue[\"name\"])\n",
    "        \n",
    "        if \"categories\" in venue:\n",
    "            for venue2 in venue[\"categories\"]:\n",
    "                venues.append(venue2[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nouns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = json.loads(open(\"../School/corpora/data/words/nouns.json\").read())[\"nouns\"]\n",
    "nouns += json.loads(open(\"../School/corpora/data/words/nouns2.json\").read())[\"nouns\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**verbs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_file = json.loads(open(\"../School/corpora/data/words/verbs.json\").read())[\"verbs\"]\n",
    "\n",
    "verbs = []\n",
    "for verb in verbs_file:\n",
    "    verbs.append(verb[\"present\"])\n",
    "\n",
    "verbs += json.loads(open(\"../School/corpora/data/words/ergative_verbs.json\").read())[\"ergative_verbs\"]\n",
    "verbs += json.loads(open(\"../School/corpora/data/words/infinitive_verbs.json\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adverbs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adverbs = json.loads(open(\"../School/corpora/data/words/adverbs.json\").read())[\"adverbs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**moods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "moods = json.loads(open(\"../School/corpora/data/humans/moods.json\").read())[\"moods\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**occupations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations = json.loads(open(\"../School/corpora/data/humans/occupations.json\").read())[\"occupations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**body_parts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_parts = json.loads(open(\"../School/corpora/data/humans/bodyParts.json\").read())[\"bodyParts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sight_verbs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sight_verbs = [\n",
    "    'see',\n",
    "    'spot',\n",
    "    'notice',\n",
    "    'find',\n",
    "    'observe',\n",
    "    'identify',\n",
    "    'glimpse',\n",
    "    'discern',\n",
    "    'perceive',\n",
    "    'catch site of',\n",
    "    'make out',\n",
    "    'pick out',\n",
    "    'distinguish',\n",
    "    'recognize',\n",
    "    'detect',\n",
    "    'note',\n",
    "    'behold',\n",
    "    'observe',\n",
    "    'view',\n",
    "    'discover',\n",
    "    'encounter'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**passages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = json.loads(open(\"../School/corpora/data/architecture/passages.json\").read())[\"passages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre_fortune**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_fortune = [\n",
    "    \"Who are you to \",\n",
    "    \"What does it mean to \",\n",
    "    \"Why must you \",\n",
    "    \"How can you \",\n",
    "    \"When will you \",\n",
    "    \"Where do you \"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fortunes** + **actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck = json.loads(open(\"../School/corpora/data/divination/tarot_interpretations.json\").read())[\"tarot_interpretations\"]\n",
    "\n",
    "fortunes = []\n",
    "actions = []\n",
    "for card in deck:\n",
    "    for fortune in card[\"fortune_telling\"]:\n",
    "        fortunes.append(fortune)\n",
    "    for light in card[\"meanings\"][\"light\"]:\n",
    "        actions.append(light)\n",
    "    for shadow in card[\"meanings\"][\"shadow\"]:\n",
    "        actions.append(shadow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Line Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i_saw**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_saw = [\n",
    "    '#venue.a.capitalize# #verb.ed# past',\n",
    "    '#occupation.a.capitalize# with #adjective.a# #body_part#',\n",
    "    '#adjective.a.capitalize# #object# #object_verb#'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**then_it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "then_it = [\n",
    "    'The #venue# now #rhyme_s2#',\n",
    "    'The #occupation# #rhyme_s2#',\n",
    "    'The #object# #rhyme_s2#'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**it_found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_found = [\n",
    "    '#now_suddenly.capitalize# inside the #venue#, I hear',\n",
    "    'The #occupation# #found_followed# me and says',\n",
    "    'The #object# #found_followed# me and says'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stations(file):\n",
    "    all_stations = []\n",
    "    \n",
    "    for station in file[\"stations\"]:\n",
    "        all_stations.append(station[\"name\"])\n",
    "        \n",
    "    return all_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Directions Between Two Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directions(start, end, all_shuffled_stations):\n",
    "    directions = {}\n",
    "    for station in file[\"stations\"]:\n",
    "        if station[\"name\"] == start:\n",
    "            start_lines = station[\"lines\"]\n",
    "            \n",
    "        if station[\"name\"] == end:\n",
    "            end_lines = station[\"lines\"]\n",
    "        \n",
    "    directions[\"start\"] = start\n",
    "    \n",
    "    while len(directions) == 1:\n",
    "        next_line = random.choice(start_lines)\n",
    "        stations = all_shuffled_stations[next_line]\n",
    "        \n",
    "        not_found = True\n",
    "        for this_station in stations:\n",
    "            if not_found:\n",
    "                for station in file[\"stations\"]:\n",
    "                    if not_found:\n",
    "                        if station[\"name\"] == this_station:\n",
    "                            this_station_lines = station[\"lines\"]\n",
    "\n",
    "                            for line in this_station_lines:\n",
    "                                if not_found:\n",
    "                                    if line in end_lines:\n",
    "                                        directions[\"first_line\"] = next_line\n",
    "                                        directions[\"transfer_station\"] = this_station\n",
    "                                        directions[\"second_line\"] = line\n",
    "\n",
    "                                        not_found = False\n",
    "                    \n",
    "\n",
    "    directions[\"end\"] = end\n",
    "\n",
    "    return directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme(word):\n",
    "    phones = pronouncing.phones_for_word(word)\n",
    "    phone_parts = pronouncing.rhyming_part(phones[0])\n",
    "    rhymes = pronouncing.search(phone_parts + \"$\")\n",
    "    \n",
    "    # ensures rhyming word is not the same as given word\n",
    "    rhyme = word.lower()\n",
    "    while rhyme == word.lower():\n",
    "        rhyme = random.choice(rhymes)\n",
    "    \n",
    "    return rhyme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fortune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fortune(word):\n",
    "    phones = pronouncing.phones_for_word(word)\n",
    "    phone_parts = pronouncing.rhyming_part(phones[0])\n",
    "    rhymes = pronouncing.search(phone_parts + \"$\")\n",
    "    \n",
    "    for fortune in fortunes:\n",
    "        last_word = fortune.split(\" \")[-1]\n",
    "        if last_word in rhymes:\n",
    "            return fortune, \"fortune\"\n",
    "    \n",
    "    for action in actions:\n",
    "        last_word = action.split(\" \")[-1]\n",
    "        if last_word in rhymes:\n",
    "            return action, \"action\"\n",
    "    \n",
    "    return \"Sorry!\", \"error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function: Plural\n",
    "\n",
    "Credit: [pytracery/tracery/modifiers.py](https://github.com/aparrish/pytracery/blob/5800d1bbc91183c02eda61353b09bd8969c5b91a/tracery/modifiers.py#L29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plural(word):\n",
    "    if word[-1] in \"shxSHX\":\n",
    "        return word + \"es\"\n",
    "    \n",
    "    elif word[-1] in \"yY\":\n",
    "        if word[-2] not in \"aeiouAEIOU\":\n",
    "            return word[:-1] + \"ies\"\n",
    "        else:\n",
    "            return word + \"s\"\n",
    "        \n",
    "    else:\n",
    "        return word + \"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(directions):\n",
    "    # poem constants\n",
    "    weather = random.choice(weathers)\n",
    "    \n",
    "    if weather[-1] == \"s\":\n",
    "        is_are = \"are\"\n",
    "    else:\n",
    "        is_are = \"is\"\n",
    "        \n",
    "    version = random.randint(0,2)\n",
    "    venue = random.choice(venues)\n",
    "    occupation = random.choice(occupations)\n",
    "    body_part = random.choice(body_parts)\n",
    "    object = random.choice(objects)\n",
    "    object_verb = plural(random.choice(verbs))\n",
    "    passage = random.choice(passages)\n",
    "    \n",
    "    # rhymes\n",
    "    start_split = directions[\"start\"].split(\" \")\n",
    "    rhyme_s1 = get_rhyme(start_split[-1])\n",
    "    \n",
    "    if version == 0:\n",
    "        rhyme_s2 = get_rhyme(\"past\")\n",
    "    elif version == 1:\n",
    "        rhyme_s2 = get_rhyme(body_part)\n",
    "    elif version == 2:\n",
    "        rhyme_s2 = get_rhyme(object_verb)\n",
    "        \n",
    "    end_split = directions[\"end\"].split(\" \")\n",
    "    fortune, fortune_type = get_fortune(end_split[-1])\n",
    "    if fortune_type == \"action\":\n",
    "        fortune = fortune.lower()\n",
    "        fortune = \"You are \" + fortune\n",
    "    elif fortune_type == \"error\":\n",
    "        fortune = get_rhyme(end_split[-1])\n",
    "        fortune = random.choice(pre_fortune) + fortune + \"?\"\n",
    "    \n",
    "    rhyme_s3 = get_rhyme(end_split[-1])\n",
    "    \n",
    "    poem_rules = {\n",
    "        'origin': '''\n",
    "            In London, the #weather.lowercase# #is_are# #adjective#\n",
    "            I #movement_verb# #preposition# the #thing# and #verb# into #start#\n",
    "            #adverb.capitalize#, I #movement_verb# onto the #first_line# line\n",
    "            My #mood# #adverb# #rhyme_s1#\n",
    "            \n",
    "            I transferred at #transfer_station#\n",
    "            #i_saw#\n",
    "            I #sight_verb# #passage.a# #preposition# the #second_line# line car\n",
    "            #then_it#\n",
    "            \n",
    "            #verb.capitalize#ing into the #passage#\n",
    "            I am #preposition# #end#\n",
    "            #it_found#\n",
    "            \"#fortune#\"\n",
    "            The #weather.lowercase# now feels #rhyme_s3#\n",
    "        ''',\n",
    "        \n",
    "        'weather': [weather],\n",
    "        'is_are': [is_are],\n",
    "        'adjective': adjectives,\n",
    "        'movement_verb': movement_verbs,\n",
    "        'preposition': prepositions,\n",
    "        'thing': objects + venues + nouns,\n",
    "        'verb': verbs,\n",
    "        'start': [directions[\"start\"]],\n",
    "        'adverb': adverbs,\n",
    "        'first_line': [directions[\"first_line\"]],\n",
    "        'mood': moods,\n",
    "        'rhyme_s1': [rhyme_s1],\n",
    "        'transfer_station': [directions[\"transfer_station\"]],\n",
    "        'venue': [venue],\n",
    "        'occupation': [occupation],\n",
    "        'body_part': [body_part],\n",
    "        'object': [object],\n",
    "        'object_verb': [object_verb],\n",
    "        'i_saw': [i_saw[version]],\n",
    "        'sight_verb': sight_verbs,\n",
    "        'passage': [passage],\n",
    "        'second_line': [directions[\"second_line\"]],\n",
    "        'rhyme_s2': [rhyme_s2],\n",
    "        'then_it': [then_it[version]],\n",
    "        'end': [directions[\"end\"]],\n",
    "        'now_suddenly': [\"now\", \"suddenly\"],\n",
    "        'found_followed': [\"found\", \"followed\"],\n",
    "        'it_found': [it_found[version]],\n",
    "        'fortune': [fortune],\n",
    "        'rhyme_s3': [rhyme_s3]\n",
    "    }\n",
    "    poem_grammar = tracery.Grammar(poem_rules)\n",
    "    poem_grammar.add_modifiers(base_english)\n",
    "    return poem_grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tube Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize All Stations by Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_stations(file):\n",
    "    stationsbyline = {}\n",
    "    for station in file[\"stations\"]:\n",
    "        for line in station[\"lines\"]:\n",
    "            if line not in stationsbyline:\n",
    "                stationsbyline[line] = [station[\"name\"]]\n",
    "            else:\n",
    "                stationsbyline[line].append(station[\"name\"])\n",
    "                \n",
    "    return stationsbyline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle All Stations by Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_all_stations(stationsbyline):\n",
    "    all_shuffled_stations = {}\n",
    "    \n",
    "    for line in list(stationsbyline.keys()):\n",
    "        stations = stationsbyline[line]\n",
    "\n",
    "        shuffled_stations = []\n",
    "        for i in range(len(stations)):\n",
    "            station = random.choice(stations)\n",
    "            shuffled_stations.append(station)\n",
    "            stations.pop(stations.index(station))\n",
    "        \n",
    "        all_shuffled_stations[line] = shuffled_stations\n",
    "\n",
    "    return all_shuffled_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Random Points for Each Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_points(all_shuffled_stations, width, height, station_distance):\n",
    "    all_points = {}\n",
    "    all_points_stations = {}\n",
    "    \n",
    "    for line in all_shuffled_stations:\n",
    "        points = {}\n",
    "\n",
    "        cur_x = random.randint(0, width)\n",
    "        cur_y = random.randint(0, height)\n",
    "        \n",
    "        for station in all_shuffled_stations[line]:\n",
    "            if station in all_points_stations:\n",
    "                points[station] = (all_points_stations[station][0], all_points_stations[station][1])\n",
    "\n",
    "                cur_x = all_points_stations[station][0]\n",
    "                cur_y = all_points_stations[station][1]\n",
    "\n",
    "            else:\n",
    "                low_x = cur_x - station_distance\n",
    "                high_x = cur_x + station_distance\n",
    "                low_y = cur_y - station_distance\n",
    "                high_y = cur_y + station_distance\n",
    "\n",
    "                # pixel buffer of 7 ensures station points aren't cut off\n",
    "                if low_x < 7:\n",
    "                    low_x = 7\n",
    "                if high_x > width-7:\n",
    "                    high_x = width-7\n",
    "                if low_y < 7:\n",
    "                    low_y = 7\n",
    "                if high_y > height-7:\n",
    "                    high_y = height-7\n",
    "\n",
    "                x = random.randint(low_x, high_x)\n",
    "                y = random.randint(low_y, high_y)\n",
    "\n",
    "                points[station] = (x,y)\n",
    "\n",
    "                cur_x = x\n",
    "                cur_y = y\n",
    "            \n",
    "        all_points[line] = points\n",
    "        \n",
    "        for line in all_points:\n",
    "            for station in all_points[line]:\n",
    "                all_points_stations[station] = all_points[line][station]\n",
    "    \n",
    "    return all_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate HTML of Interactive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_html(width, height, all_points, start, end):\n",
    "    all_ellipses = \"\"\n",
    "    all_points_str = []\n",
    "    all_lines = []\n",
    "    \n",
    "    # draw all ellipses at station points\n",
    "    for points in all_points:\n",
    "        points_str = \"\"\n",
    "    \n",
    "        for key, value in all_points[points].items():\n",
    "            rules = {\n",
    "                'origin': '<ellipse id=\"#tag#\" class=\"#line#\" cx=\"#cx#\" cy=\"#cy#\" rx=\"5\" ry=\"5\" />',\n",
    "                'tag': [key],\n",
    "                'cx': [str(value[0])],\n",
    "                'cy': [str(value[1])],\n",
    "                'line': [points.replace(\" \",\"_\")],\n",
    "            }\n",
    "\n",
    "            grammar = tracery.Grammar(rules)\n",
    "            all_ellipses += grammar.flatten(\"#origin#\")\n",
    "\n",
    "            points_str += str(value[0]) + \",\" + str(value[1]) + \" \"\n",
    "            \n",
    "        all_points_str.append(points_str)\n",
    "        all_lines.append(points.replace(\" \",\"_\"))\n",
    "\n",
    "    # iterate over lines to get line checkboxes and polygons\n",
    "    line_inputs = \"\"\n",
    "    polygon_divs = \"\"\n",
    "    \n",
    "    for line in all_lines:\n",
    "        checked = \"checked\"\n",
    "#         checked = \"\"\n",
    "#         if line == start or line == end:\n",
    "#             checked = \"checked\"\n",
    "            \n",
    "        line_rules = {\n",
    "            'origin': '<input type=\"checkbox\" class=\"legend\" id=\"#line#\" #checked#><label for=\"#line#\">#line_text#</label>',\n",
    "            'line': [line],\n",
    "            'line_text': [line.replace(\"_\",\" \").replace(\"and\", \"&amp;\")],\n",
    "            'checked': [checked]\n",
    "        }\n",
    "        line_grammar = tracery.Grammar(line_rules)\n",
    "        line_inputs += line_grammar.flatten(\"#origin#\")\n",
    "        \n",
    "        polygon_rules = {\n",
    "            'origin': '<polygon class=\"#line#\" points=\"#points#\" style=\"stroke: #stroke#;\" />',\n",
    "            'line': [line],\n",
    "            'points': [all_points_str[all_lines.index(line)]],\n",
    "            'stroke': [STATION_COLORS[line]],\n",
    "        }\n",
    "        polygon_grammar = tracery.Grammar(polygon_rules)\n",
    "        polygon_divs += polygon_grammar.flatten(\"#origin#\")\n",
    "    \n",
    "    # HTML page\n",
    "    rules = {\n",
    "        'origin': '''\n",
    "            <head>\n",
    "                <title>London Underground Map</title>\n",
    "                \n",
    "                <style>\n",
    "                    @font-face{font-family: Johnston; src: url('johnston.ttf');}\n",
    "                    body{margin: 0; padding: 25px; font-family: Johnston;}\n",
    "                        p{margin: 0; font-size: 16px;}\n",
    "                        .station{position: absolute; background-color: white;}\n",
    "                            span{display: block; padding: 2.5px 5px;}\n",
    "                        .legend{margin: 0 5px 5px 15px;}\n",
    "                        svg{display: block; margin: 25px auto 0 auto;}\n",
    "                            polygon{fill: none; stroke-width: 3;}\n",
    "                            ellipse{fill: white; stroke: black; stroke-width: 2;}\n",
    "                </style>\n",
    "                \n",
    "                <script src=\"https://ajax.aspnetcdn.com/ajax/jQuery/jquery-3.4.0.min.js\"></script>\n",
    "                <script>\n",
    "                    $(document).on('mousemove', function(e){\n",
    "                        $('.station').offset({\n",
    "                            left: e.pageX + 10,\n",
    "                            top: e.pageY + 10\n",
    "                        });\n",
    "                    });\n",
    "                    \n",
    "                    $(document).ready(function(){\n",
    "                        //$(\".legend\").each(function(){\n",
    "                        //    if ($(this).is(\":checked\")){\n",
    "                        //        var line = $(this).attr(\"id\");\n",
    "                        //        $(\".\" + line).css(\"display\", \"block\");\n",
    "                        //    }\n",
    "                        //});\n",
    "                        \n",
    "                        $(\"ellipse\").on(\"mouseenter\", function(){\n",
    "                            $(\".station\").html('<span>' + $(this).attr(\"id\") + '</span>');\n",
    "                        });\n",
    "\n",
    "                        $(\"ellipse\").on(\"mouseleave\", function(){\n",
    "                            $(\".station\").html(\"\");\n",
    "                        });\n",
    "\n",
    "                        $(\".legend\").on(\"change\", function(){\n",
    "                            var line = $(this).attr(\"id\");\n",
    "                            \n",
    "                            if ($(this).is(\":checked\")){\n",
    "                                $(\".\" + line).css(\"display\", \"block\");\n",
    "                            }\n",
    "                            else{\n",
    "                                $(\".\" + line).css(\"display\", \"none\");\n",
    "                            }\n",
    "                        });\n",
    "                    });\n",
    "                </script>\n",
    "            </head>\n",
    "            <body>\n",
    "                <h1>London Underground Map</h1>\n",
    "                <p class=\"station\"></p>\n",
    "                #lines#\n",
    "                <svg width=\"#width#\" height=\"#height#\">#polygons##all_ellipses#</svg>\n",
    "            </body>\n",
    "        ''',\n",
    "        'width': [width],\n",
    "        'height': [height],\n",
    "        'lines': [line_inputs],\n",
    "        'polygons': [polygon_divs],\n",
    "        'all_ellipses': [all_ellipses]\n",
    "    }\n",
    "\n",
    "    grammar = tracery.Grammar(rules)\n",
    "    return grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 1200\n",
    "HEIGHT = 650\n",
    "\n",
    "STATION_COLORS = {\n",
    "    \"Bakerloo\": \"rgb(176, 93, 16)\",\n",
    "    \"Central\": \"rgb(237, 46, 36)\",\n",
    "    \"Circle\": \"rgb(252, 207, 5)\",\n",
    "    \"District\": \"rgb(0, 130, 59)\",\n",
    "    \"Hammersmith_and_City\": \"rgb(242, 136, 161)\",\n",
    "    \"Jubilee\": \"rgb(149, 156, 161)\",\n",
    "    \"Metropolitan\": \"rgb(150, 2, 93)\",\n",
    "    \"Northern\": \"rgb(33, 30, 30)\",\n",
    "    \"Piccadilly\": \"rgb(28, 64, 148)\",\n",
    "    \"Victoria\": \"rgb(7, 159, 219)\",\n",
    "    \"Waterloo_and_City\": \"rgb(133, 204, 187)\",\n",
    "}\n",
    "\n",
    "STATION_DISTANCE = 175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            In London, the heavy blowing snow is surrogate\n",
      "            I ran because of the shrine and queue into Kentish Town\n",
      "            Punctually, I shimmied onto the Northern line\n",
      "            My enriched mood swiftly run-down\n",
      "            \n",
      "            I transferred at Highgate\n",
      "            A Buddhist temple flowered past\n",
      "            I detect a passage as opposed to the Northern line car\n",
      "            The Buddhist temple now assed\n",
      "            \n",
      "            Searching into the passage\n",
      "            I am past Hampstead\n",
      "            Suddenly inside the Buddhist temple, I hear\n",
      "            \"When will you marblehead?\"\n",
      "            The heavy blowing snow now feels brodhead\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "file = json.loads(open(\"../School/corpora/data/geography/london_underground_stations.json\").read())\n",
    "all_stations = get_all_stations(file)\n",
    "stationsbyline = organize_stations(file)\n",
    "\n",
    "start = random.choice(all_stations)\n",
    "end = start\n",
    "# This ensures start and end station are different\n",
    "while start == end:\n",
    "    end = random.choice(all_stations)\n",
    "\n",
    "all_shuffled_stations = shuffle_all_stations(stationsbyline)\n",
    "directions = get_directions(start, end, all_shuffled_stations)\n",
    "\n",
    "all_points = get_all_points(all_shuffled_stations, WIDTH, HEIGHT, STATION_DISTANCE)\n",
    "\n",
    "# Poem\n",
    "print(generate_poem(directions))\n",
    "\n",
    "# Map\n",
    "html = build_all_html(str(WIDTH), str(HEIGHT), all_points, directions[\"first_line\"], directions[\"second_line\"])\n",
    "tube_map = open(\"london_underground_map.html\",\"w\").write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tubemap](map1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
