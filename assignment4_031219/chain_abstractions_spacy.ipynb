{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Abstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Words and Clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = json.load(open(\"../../corpora/data/words/word_clues/clues_four.json\"))\n",
    "five = json.load(open(\"../../corpora/data/words/word_clues/clues_five.json\"))\n",
    "six = json.load(open(\"../../corpora/data/words/word_clues/clues_six.json\"))\n",
    "\n",
    "source = dict(four[\"data\"], **five[\"data\"], **six[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Compound Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = json.load(open(\"../../corpora/data/words/compounds.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fed a compound word (e.x. foothill), this function will take the second inner word (e.x. hill) and find another that has a matching first (e.x. hilltop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatch(i, this_thread, compounds):\n",
    "    for j in compounds[\"compounds\"]:\n",
    "        if i[\"secondWord\"] == j[\"firstWord\"]:\n",
    "            if len(this_thread) == 0 or i != this_thread[-1]:\n",
    "                this_thread.append(i)\n",
    "            this_thread.append(j)\n",
    "            i = j\n",
    "            this_thread = findMatch(i, this_thread, compounds)\n",
    "            break\n",
    "            \n",
    "    return this_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all possible threads in compounds.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_threads = []\n",
    "this_thread = []\n",
    "\n",
    "for i in compounds[\"compounds\"]:\n",
    "    final_thread = findMatch(i, this_thread, compounds)\n",
    "    \n",
    "    if len(final_thread) != 0:\n",
    "        all_threads.append(final_thread)\n",
    "        \n",
    "    this_thread = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Threads to Clues\n",
    "\n",
    "1. Set a thread in all_threads to poem_thread\n",
    "2. Take first word in poem_thread\n",
    "3. Try to find match in clue words\n",
    "4. If match, set key (firstWord, secondWord) tuple to clue list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poem_threads_all = []\n",
    "poem_thread = {}\n",
    "\n",
    "for thread in all_threads:\n",
    "    for i in range(len(thread)):\n",
    "        if thread[i][\"firstWord\"] in source.keys():\n",
    "            this_word = (thread[i][\"firstWord\"],thread[i][\"secondWord\"])\n",
    "            poem_thread[this_word] = source[thread[i][\"firstWord\"]]\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    poem_threads_all.append(poem_thread)\n",
    "    poem_thread = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up poem_threads; delete empty or 1 word threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_threads_len = len(poem_threads_all)\n",
    "poem_threads = []\n",
    "\n",
    "for i in range(poem_threads_len - 1):\n",
    "    if len(poem_threads_all[i]) > 1:\n",
    "        poem_threads.append(poem_threads_all[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Nouns, Verbs, Adjectives, and Prepositions\n",
    "\n",
    "Gather a dataset of nouns, verbs, adjectives, and prepositions to reference words to in hopes of finding its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nouns = \"a/an\"\n",
    "- Verbs = \"to\"\n",
    "- Adjectivess/Prepositionss = \"to be\"\n",
    "- Not Found = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getType(word):\n",
    "    doc = nlp(word)\n",
    "    \n",
    "    for word in doc:\n",
    "        if word.pos_ == \"ADJ\" or word.pos_ == \"ADP\":\n",
    "            return \"to be\"\n",
    "\n",
    "        elif word.pos_ == \"VERB\":\n",
    "            return \"to\"\n",
    "\n",
    "        elif word.pos_ == \"NOUN\":\n",
    "            return \"a\"\n",
    "\n",
    "        else:\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it All Together!\n",
    "\n",
    "Take a random poem thread, get types, and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be down\n",
      "    is to be not up,\n",
      "            but to be downstream is\n",
      "a stream\n",
      "    is a water source,\n",
      "          but a streamline is\n",
      "a line?\n"
     ]
    }
   ],
   "source": [
    "poem_thread = random.choice(poem_threads)\n",
    "\n",
    "last_phrase = \"\"\n",
    "last_word = \"\"\n",
    "first = True\n",
    "\n",
    "for key,value in poem_thread.items():\n",
    "    rules = {\n",
    "        \"body_first\": \"#phrase.capitalize# #word#\\n    is #phrase# #clue#,\\n#numSpace#but #phrase# #compound# is\",\n",
    "        \"body_noun_first\": \"#word.a.capitalize#\\n    is #clue.a#,\\n#numSpace#but #compound.a# is\",\n",
    "        \n",
    "        \"body\": \"#phrase# #word#\\n    is #phrase# #clue#,\\n#numSpace#but #phrase# #compound# is\",\n",
    "        \"body_noun\": \"#word.a#\\n    is #clue.a#,\\n#numSpace#but #compound.a# is\",\n",
    "\n",
    "        \"phrase\": getType(key[0]),\n",
    "        \"word\": key[0],\n",
    "        \"clue\": value,\n",
    "        \"numSpace\": \" \"*(len(\"#clue#\") + len(key[1])),\n",
    "        \"compound\": key[0] + key[1]\n",
    "    }\n",
    "\n",
    "    grammar = tracery.Grammar(rules)\n",
    "    grammar.add_modifiers(base_english)\n",
    "    \n",
    "    if first and getType(key[0]) == \"a\":\n",
    "        print(grammar.flatten(\"#body_noun_first#\"))\n",
    "        first = False\n",
    "        \n",
    "    elif first:\n",
    "        print(grammar.flatten(\"#body_first#\"))\n",
    "        first = False\n",
    "        \n",
    "    elif getType(key[0]) == \"a\":\n",
    "        print(grammar.flatten(\"#body_noun#\"))\n",
    "        \n",
    "    else:\n",
    "        print(grammar.flatten(\"#body#\"))\n",
    "    \n",
    "    last_phrase = getType(key[0])\n",
    "    last_word = key[1]\n",
    "\n",
    "\n",
    "last_line_rules = {\n",
    "    \"last\": \"#phrase# #word#?\",\n",
    "    \"last_noun\": \"#word.a#?\",\n",
    "    \"phrase\": last_phrase,\n",
    "    \"word\": last_word\n",
    "}\n",
    "grammar = tracery.Grammar(last_line_rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "\n",
    "if last_phrase == \"a\":\n",
    "    print(grammar.flatten(\"#last_noun#\"))\n",
    "\n",
    "else:\n",
    "    print(grammar.flatten(\"#last#\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
